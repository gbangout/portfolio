# Mon portfolio projets Data:

## Projets Big Data

## [Projet Big Data: Netflix Analytics](https://github.com/gbangout/projet-big-data-netflix-analytics.git)
Besoin métier : Aider l’équipe produit à identifier les genres et zones géographiques à fort potentiel en analysant le catalogue existant pour orienter les décisions de contenu.

Approche : Cadrage des indicateurs utiles, ingestion et nettoyage des données à l’échelle (PySpark), enrichissement et structuration en base analytique (PostgreSQL), calculs distribués (Spark SQL) puis restitution visuelle des tendances (genres, pays, ratings, évolution temporelle) orientée décision.

Stack : PySpark, Pandas, Spark SQL, PostgreSQL, visualisations type BI.

Résultat : Identification des segments sous-exploités mais en croissance, catalogue prêt à être branché sur un dashboard ou pipeline produit.

## [Projet Big Data: Investissement dans Airbnb à Paris](https://github.com/gbangout/projet-big-data-investissement-airbnb.git)

Besoin métier simulé : Identifier les zones à fort rendement locatif pour guider une stratégie d’investissement immobilier sur Airbnb.

Approche : Ingestion et nettoyage des listings et avis utilisateurs, structuration des données (PostgreSQL) et automatisation des flux (NiFi), calculs distribués (Spark) et analyse des KPI (prix, taux d’occupation, attractivité zone).

Stack : Python, NiFi, Spark, PostgreSQL, visualisation BI.

Résultat : Mise en place d’une base analytique exploitable permettant de prioriser les quartiers à fort potentiel ROI.

## [Projet Big Data: Conception d’une solution Big Data pour optimiser la logistique](https://github.com/gbangout/gestion-de-projet-big-data-logistics.git)
Besoin métier : Améliorer la performance logistique en réduisant les retards de livraison, détectant des pannes et améliorant satisfaction client.

Approche : Conception d’une architecture Big Data temps réel : ingestion IoT + transactions (Kafka/NiFi), stockage distribué (Hadoop), traitement streaming (Spark Streaming), stockage NoSQL et dashboards opérationnels.

Stack : Kafka, NiFi, Hadoop, Spark, MongoDB/Cassandra, PowerBI/Tableau/Kibana.

Résultat : Détection anticipée des anomalies et optimisation de la chaîne logistique — base prête à connecter à des alertes temps réel et dashboards métier.

## Projets Machine Learning (ML, NLP)

## [Projet NLP Text Mining: Analyse et prédiction des sentiments de tweets](https://github.com/gbangout/text-mining-sentiment.git)
Besoin métier : Comprendre la perception des utilisateurs vis-à-vis d’une marque à partir des tweets.

Approche : Préparation et vectorisation des textes, entraînement d’un modèle de classification binaire des sentiments (positif / négatif).

Stack : Python, scikit-learn, pandas, nltk, TF-IDF, régression logistique.

Résultat : Modèle de classification des sentiments opérationnel pour analyser en continu la tonalité des retours utilisateurs.


## [Projet ML clustering rapport sientifique: Analyse de la tendance de la pollution en Europe](https://www.eionet.europa.eu/etcs/etc-he/products/etc-he-products/etc-he-reports/etc-he-report-2023-8-long-term-trends-of-air-pollutants-at-european-and-national-level-2005-2021)
Clustering des tendances à long terme des polluants en Europe

## [Projet ML : Prédiction de souscription bancaire](https://github.com/gbangout-apziva/term-deposit.git)
Développement d’un modèle prédictif pour estimer si un client souscrit à un dépôt à terme. Mise en œuvre d’une validation croisée à 5 plis pour évaluer la robustesse du modèle et optimisation afin d’atteindre un score moyen de performance supérieur à 81 %.
